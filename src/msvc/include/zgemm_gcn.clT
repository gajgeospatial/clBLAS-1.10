/*******************************************************************************
 * Notes:
 * for column major, id(0) is row so C data is coalesced
 * for row major, id(0) is col
 ******************************************************************************/

static const char * zgemm_NT_64_32_8_16x16_2x4__ALPHABETA = "\
\n\
\n\
// convert preprocs to ints for comparison\n\
#define _S_ 1\n\
#define _D_ 2\n\
#define _C_ 3\n\
#define _Z_ 4\n\
\n\
/*******************************************************************************\n\
 * Pre-Processor "Strings"\n\
 ******************************************************************************/\n\
#define COLUMN_MAJOR_STR      ColMajor\n\
#define ROW_MAJOR_STR         RowMajor\n\
\n\
/*******************************************************************************\n\
 * Kernel PreProcessor Definitions\n\
 ******************************************************************************/\n\
#define WG_NUM_ROWS           16\n\
#define WG_NUM_COLS           16\n\
#define MICRO_TILE_NUM_ROWS   2\n\
#define MICRO_TILE_NUM_COLS   4\n\
#define NUM_UNROLL_ITER       8\n\
#define ORDER                 ColMajor\n\
#define TRANSPOSE_A           N\n\
#define TRANSPOSE_B           T\n\
#define DATA_TYPE             _Z_\n\
\n\
#define MACRO_TILE_NUM_ROWS   32\n\
#define MACRO_TILE_NUM_COLS   64\n\
// each row lengthened by this ammount\n\
#define LOCAL_ROW_PAD         1\n\
// each col lengthened by this ammount\n\
#define LOCAL_COL_PAD         1\n\
\n\
\n\
/*******************************************************************************\n\
 * Global Memory Indices\n\
 * Note: (a==b)==(c==d) means if both are true or neither is true\n\
 ******************************************************************************/\n\
\n\
/* col-major non-transposed\n\
 * row-major transposed */\n\
#define GET_GLOBAL_INDEX_N(ROW,COL,STRIDE) ((COL)*(STRIDE)+(ROW))\n\
\n\
/* col-major transposed\n\
 * row-major non-transposed */\n\
#define GET_GLOBAL_INDEX_T(ROW,COL,STRIDE) ((ROW)*(STRIDE)+(COL))\n\
\n\
// global A\n\
"
"\
#if (ORDER==COLUMN_MAJOR_STR) == (TRANSPOSE_A==N)\n\
#define GET_GLOBAL_INDEX_A(ROW,COL) GET_GLOBAL_INDEX_N((ROW),(COL),(lda))\n\
#else\n\
#define GET_GLOBAL_INDEX_A(ROW,COL) GET_GLOBAL_INDEX_T((ROW),(COL),(lda))\n\
#endif\n\
\n\
// global B\n\
#if (ORDER==COLUMN_MAJOR_STR) == (TRANSPOSE_B==N)\n\
#define GET_GLOBAL_INDEX_B(ROW,COL) GET_GLOBAL_INDEX_T((ROW),(COL),(ldb))\n\
#else\n\
#define GET_GLOBAL_INDEX_B(ROW,COL) GET_GLOBAL_INDEX_N((ROW),(COL),(ldb))\n\
#endif\n\
\n\
// global C\n\
#if (ORDER==COLUMN_MAJOR_STR)\n\
#define GET_GLOBAL_INDEX_C(ROW,COL) GET_GLOBAL_INDEX_N((ROW),(COL),(ldc))\n\
#else\n\
#define GET_GLOBAL_INDEX_C(ROW,COL) GET_GLOBAL_INDEX_T((ROW),(COL),(ldc))\n\
#endif\n\
\n\
/*******************************************************************************\n\
 * Local Memory Indices\n\
 ******************************************************************************/\n\
\n\
// localA - rotated 90 degrees from B but use same accessor unless slow\n\
#define GET_LOCAL_INDEX_A(ROW,COL) (ROW + COL*(MACRO_TILE_NUM_ROWS+LOCAL_COL_PAD) )\n\
#define GET_LOCAL_STEP_A ( ((MACRO_TILE_NUM_COLS)+(LOCAL_ROW_PAD)) \\n\
    * ((WG_NUM_ROWS)*(WG_NUM_COLS)/(MACRO_TILE_NUM_COLS))\n\
\n\
// localB\n\
#define GET_LOCAL_INDEX_B(ROW,COL) ((COL) + (ROW)*((MACRO_TILE_NUM_COLS)+(LOCAL_ROW_PAD)) )\n\
#define GET_LOCAL_STEP_B ( ((MACRO_TILE_NUM_COLS)+(LOCAL_ROW_PAD)) \\n\
    * ((WG_NUM_ROWS)*(WG_NUM_COLS)/(MACRO_TILE_NUM_COLS))\n\
\n\
/*******************************************************************************\n\
 * Data Types\n\
 ******************************************************************************/\n\
\n\
// single precision\n\
#if DATA_TYPE==_S_\n\
#define DATA_TYPE_STR         float\n\
#define DATA_TYPE_CHAR        s\n\
#define TYPE_MAD(MUL0,MUL1,DST) DST = mad(MUL0,MUL1,DST);\n\
#define TYPE_MAD2( DST, ALPHA, REG, BETA ) DST = (ALPHA)*(REG) + (BETA)*(DST);\n\
\n\
// double precision\n\
#elif DATA_TYPE==_D_\n\
#define DATA_TYPE_STR         double\n\
#define DATA_TYPE_CHAR        d\n\
#define TYPE_MAD(MUL0,MUL1,DST) DST = mad(MUL0,MUL1,DST);\n\
"
"\
#define TYPE_MAD2( DST, ALPHA, REG, BETA ) DST = (ALPHA)*(REG) + (BETA)*(DST);\n\
\n\
// complex single precision\n\
#elif DATA_TYPE==_C_\n\
#define DATA_TYPE_STR         float2\n\
#define DATA_TYPE_CHAR        c\n\
#define TYPE_MAD(MUL0,MUL1,DST) \\n\
  DST.s0 = mad(  MUL0.s0, MUL1.s0, DST.s0 ); \\n\
  DST.s0 = mad( -MUL0.s1, MUL1.s1, DST.s0 ); \\n\
  DST.s1 = mad(  MUL0.s0, MUL1.s1, DST.s1 ); \\n\
  DST.s1 = mad(  MUL0.s1, MUL1.s0, DST.s1 );\n\
#define TYPE_MAD2( DST, ALPHA, REG, BETA ) \\n\
  /* (1) */ \\n\
  type_mad2_tmp = REG.s0; \\n\
  REG.s0 *= ALPHA.s0; \\n\
  REG.s0 = mad( -ALPHA.s1, REG.s1, REG.s0 ); \\n\
  REG.s1 *= ALPHA.s0; \\n\
  REG.s1 = mad(  ALPHA.s1, type_mad2_tmp, REG.s1 ); \\n\
  /* (2) */ \\n\
  REG.s0 = mad(  BETA.s0, DST.s0, REG.s0 ); \\n\
  REG.s0 = mad( -BETA.s1, DST.s1, REG.s0 ); \\n\
  REG.s1 = mad(  BETA.s1, DST.s0, REG.s1 ); \\n\
  REG.s1 = mad(  BETA.s0, DST.s1, REG.s1 ); \\n\
  /* (3) */ \\n\
  DST = REG;\n\
\n\
// complex double precision\n\
#else\n\
#define DATA_TYPE_STR         double2\n\
#define DATA_TYPE_CHAR        z\n\
#define TYPE_MAD(MUL0,MUL1,DST) \\n\
  DST.s0 = mad(  MUL0.s0, MUL1.s0, DST.s0 ); \\n\
  DST.s0 = mad( -MUL0.s1, MUL1.s1, DST.s0 ); \\n\
  DST.s1 = mad(  MUL0.s0, MUL1.s1, DST.s1 ); \\n\
  DST.s1 = mad(  MUL0.s1, MUL1.s0, DST.s1 );\n\
#define TYPE_MAD2( DST, ALPHA, REG, BETA ) \\n\
  /* (1) */ \\n\
  type_mad2_tmp = REG.s0; \\n\
  REG.s0 *= ALPHA.s0; \\n\
  REG.s0 = mad( -ALPHA.s1, REG.s1, REG.s0 ); \\n\
  REG.s1 *= ALPHA.s0; \\n\
  REG.s1 = mad(  ALPHA.s1, type_mad2_tmp, REG.s1 ); \\n\
  /* (2) */ \\n\
  REG.s0 = mad(  BETA.s0, DST.s0, REG.s0 ); \\n\
  REG.s0 = mad( -BETA.s1, DST.s1, REG.s0 ); \\n\
  REG.s1 = mad(  BETA.s1, DST.s0, REG.s1 ); \\n\
  REG.s1 = mad(  BETA.s0, DST.s1, REG.s1 ); \\n\
  /* (3) */ \\n\
  DST = REG;\n\
\n\
"
"\
#endif\n\
\n\
/*******************************************************************************\n\
 * 2x4 micro tile\n\
 ******************************************************************************/\n\
#define MAD2x4 \\n\
  rA[0] = localA[offA + 0*WG_NUM_ROWS]; \\n\
  rA[1] = localA[offA + 1*WG_NUM_ROWS]; \\n\
  rB[0] = localB[offB + 0*WG_NUM_COLS]; \\n\
  rB[1] = localB[offB + 1*WG_NUM_COLS]; \\n\
  rB[2] = localB[offB + 2*WG_NUM_COLS]; \\n\
  rB[3] = localB[offB + 3*WG_NUM_COLS]; \\n\
  offA += (MACRO_TILE_NUM_ROWS+LOCAL_COL_PAD); \\n\
  offB += (MACRO_TILE_NUM_COLS+LOCAL_ROW_PAD); \\n\
  TYPE_MAD(rA[0],rB[0],rC[0][0]); \\n\
  TYPE_MAD(rA[1],rB[0],rC[1][0]); \\n\
  TYPE_MAD(rA[0],rB[1],rC[0][1]); \\n\
  TYPE_MAD(rA[1],rB[1],rC[1][1]); \\n\
  TYPE_MAD(rA[0],rB[2],rC[0][2]); \\n\
  TYPE_MAD(rA[1],rB[2],rC[1][2]); \\n\
  TYPE_MAD(rA[0],rB[3],rC[0][3]); \\n\
  TYPE_MAD(rA[1],rB[3],rC[1][3]); \\n\
  mem_fence(CLK_LOCAL_MEM_FENCE);\n\
\n\
// concatenate kernel name\n\
// zgemm_NT_64_32_8_16x16_2x4__ALPHABETA\n\
#define CONCAT_NAME(DT,TA,TB,TILE_COLS,TILE_ROWS,NUI,WGR,WGC,MTR,MTC) \\n\
  DT ## gemm_ ## TA ## TB ## _ ## TILE_COLS ## _ ## TILE_ROWS ## _ ## NUI ## _ ## WGR ## x ## WGC ## _ ## MTR ## x ## MTC ## __ALPHABETA\n\
#define KERNEL_NAME(DT,TA,TB,TILE_COLS,TILE_ROWS,NUI,WGR,WGC,MTR,MTC) CONCAT_NAME(DT,TA,TB,TILE_COLS,TILE_ROWS,NUI,WGR,WGC,MTR,MTC)\n\
\n\
/*******************************************************************************\n\
 * Kernel\n\
 ******************************************************************************/\n\
__attribute__((reqd_work_group_size(WG_NUM_COLS,WG_NUM_ROWS,1)))\n\
__kernel void KERNEL_NAME(DATA_TYPE_CHAR,TRANSPOSE_A,TRANSPOSE_B,MACRO_TILE_NUM_COLS,MACRO_TILE_NUM_ROWS,NUM_UNROLL_ITER,WG_NUM_ROWS,WG_NUM_COLS,MICRO_TILE_NUM_ROWS,MICRO_TILE_NUM_COLS) ( \n\
  uint const M,\n\
  uint const N,\n\
  uint const K,\n\
  DATA_TYPE_STR const alpha,\n\
  DATA_TYPE_STR const beta,\n\
  __global DATA_TYPE_STR const * restrict A,\n\
  __global DATA_TYPE_STR const * restrict B,\n\
  __global DATA_TYPE_STR       *          C,\n\
  uint const lda,\n\
  uint const ldb,\n\
  uint const ldc,\n\
  uint const offsetA,\n\
  uint const offsetB,\n\
  uint const offsetC )\n\
{\n\
"
"\
  // apply offsets\n\
  A += offsetA;\n\
  B += offsetB;\n\
  C += offsetC;\n\
\n\
  // registers\n\
  DATA_TYPE_STR rC[MICRO_TILE_NUM_ROWS][MICRO_TILE_NUM_COLS]  = { {0} };\n\
  DATA_TYPE_STR rA[MICRO_TILE_NUM_ROWS];\n\
  DATA_TYPE_STR rB[MICRO_TILE_NUM_COLS];\n\
    \n\
  // local memory\n\
  __local DATA_TYPE_STR localA[NUM_UNROLL_ITER*(MACRO_TILE_NUM_ROWS+LOCAL_COL_PAD)];\n\
  __local DATA_TYPE_STR localB[NUM_UNROLL_ITER*(MACRO_TILE_NUM_COLS+LOCAL_ROW_PAD)];\n\
\n\
/*  \n\
 * for coalesced C writing\n\
 * if column major, id(0) is row\n\
 * if row major, id(0) is col\n\
 */\n\
  uint groupRow = get_group_id(0);\n\
  uint groupCol = get_group_id(1);\n\
  uint localRow = get_local_id(0);\n\
  uint localCol = get_local_id(1);\n\
  uint localSerial = localRow + localCol*WG_NUM_ROWS;\n\
\n\
  /*****************************************************************************\n\
   * global indices being loaded\n\
   ****************************************************************************/\n\
  // which gAij is this thread responsible for loading?\n\
#define globalARow (groupRow*MACRO_TILE_NUM_ROWS + localSerial%MACRO_TILE_NUM_ROWS)\n\
#define globalACol (localSerial/MACRO_TILE_NUM_ROWS)\n\
#define globalAIdx (GET_GLOBAL_INDEX_A( globalARow, globalACol ) )\n\
  A += globalAIdx;\n\
  // which gBij is this thread responsible for loading?\n\
#define globalBRow (localSerial/MACRO_TILE_NUM_COLS)\n\
#define globalBCol (groupCol*MACRO_TILE_NUM_COLS + localSerial%MACRO_TILE_NUM_COLS)\n\
#define globalBIdx (GET_GLOBAL_INDEX_B( globalBRow, globalBCol ) )\n\
  B += globalBIdx;\n\
\n\
  uint block_k = K / NUM_UNROLL_ITER;\n\
#pragma nounroll\n\
  do {\n\
\n\
    /***************************************************************************\n\
     * local indices being written\n\
     **************************************************************************/\n\
    // which lAij is this thread responsible for writing?\n\
#define localARow (localSerial % MACRO_TILE_NUM_ROWS)\n\
#define localACol (localSerial / MACRO_TILE_NUM_ROWS)\n\
#define localAStride ( (MACRO_TILE_NUM_ROWS+LOCAL_COL_PAD) * (WG_NUM_ROWS*WG_NUM_COLS/MACRO_TILE_NUM_ROWS) )\n\
"
"\
#define globalAStride ( GET_GLOBAL_INDEX_A(0, (WG_NUM_ROWS*WG_NUM_COLS/MACRO_TILE_NUM_ROWS) ) )\n\
#define localAIdx ( GET_LOCAL_INDEX_A(localARow, localACol) )\n\
    __local DATA_TYPE_STR *lA = localA + localAIdx;\n\
    // which lBij is this thread responsible for writing?\n\
#define localBRow ( localSerial / MACRO_TILE_NUM_COLS )\n\
#define localBCol ( localSerial % MACRO_TILE_NUM_COLS )\n\
#define localBIdx ( GET_LOCAL_INDEX_B(localBRow, localBCol) )\n\
#define localBStride  ( (MACRO_TILE_NUM_COLS+LOCAL_ROW_PAD) * (WG_NUM_ROWS*WG_NUM_COLS/MACRO_TILE_NUM_COLS) )\n\
#define globalBStride ( GET_GLOBAL_INDEX_B( (WG_NUM_ROWS*WG_NUM_COLS/MACRO_TILE_NUM_COLS), 0 ) )\n\
    __local DATA_TYPE_STR *lB = localB + localBIdx;\n\
    barrier(CLK_LOCAL_MEM_FENCE);\n\
\n\
    /***************************************************************************\n\
     * Load global -> local\n\
     * num loads = num threads / total loads\n\
     **************************************************************************/\n\
    // 2x4 uTile x 8unroll\n\
    lA[ 0*localAStride ] = A[ 0*globalAStride ];\n\
    lB[ 0*localBStride ] = B[ 0*globalBStride ];\n\
    lB[ 1*localBStride ] = B[ 1*globalBStride ];\n\
    barrier(CLK_LOCAL_MEM_FENCE);\n\
\n\
    uint offA = localRow;\n\
    uint offB = localCol;\n\
\n\
    /***************************************************************************\n\
     * do mads in registers\n\
     **************************************************************************/\n\
    MAD2x4\n\
    MAD2x4\n\
    MAD2x4\n\
    MAD2x4\n\
    MAD2x4\n\
    MAD2x4\n\
    MAD2x4\n\
    MAD2x4\n\
\n\
    // fully shift\n\
    A += lda*NUM_UNROLL_ITER; // b/c N\n\
    B += ldb*NUM_UNROLL_ITER; // b/c T\n\
\n\
  } while (--block_k > 0);\n\
\n\
  // which global Cij is this thread responsible for computing?\n\
  uint globalCRow = groupRow * MACRO_TILE_NUM_ROWS + localRow;\n\
  uint globalCCol = groupCol * MACRO_TILE_NUM_COLS + localCol;\n\
\n\
  /***************************************************************************\n\
   * write data\n\
   **************************************************************************/\n\
"
"\
  double type_mad2_tmp; // used in TYPE_MAD2\n\
  TYPE_MAD2( C[ GET_GLOBAL_INDEX_C( globalCRow+0*WG_NUM_ROWS, globalCCol+0*WG_NUM_COLS) ], alpha, rC[0][0], beta )\n\
  TYPE_MAD2( C[ GET_GLOBAL_INDEX_C( globalCRow+0*WG_NUM_ROWS, globalCCol+1*WG_NUM_COLS) ], alpha, rC[0][1], beta )\n\
  TYPE_MAD2( C[ GET_GLOBAL_INDEX_C( globalCRow+0*WG_NUM_ROWS, globalCCol+2*WG_NUM_COLS) ], alpha, rC[0][2], beta )\n\
  TYPE_MAD2( C[ GET_GLOBAL_INDEX_C( globalCRow+0*WG_NUM_ROWS, globalCCol+3*WG_NUM_COLS) ], alpha, rC[0][3], beta )\n\
  TYPE_MAD2( C[ GET_GLOBAL_INDEX_C( globalCRow+1*WG_NUM_ROWS, globalCCol+0*WG_NUM_COLS) ], alpha, rC[1][0], beta )\n\
  TYPE_MAD2( C[ GET_GLOBAL_INDEX_C( globalCRow+1*WG_NUM_ROWS, globalCCol+1*WG_NUM_COLS) ], alpha, rC[1][1], beta )\n\
  TYPE_MAD2( C[ GET_GLOBAL_INDEX_C( globalCRow+1*WG_NUM_ROWS, globalCCol+2*WG_NUM_COLS) ], alpha, rC[1][2], beta )\n\
  TYPE_MAD2( C[ GET_GLOBAL_INDEX_C( globalCRow+1*WG_NUM_ROWS, globalCCol+3*WG_NUM_COLS) ], alpha, rC[1][3], beta )\n\
   \n\
}\n\
\n\
";



